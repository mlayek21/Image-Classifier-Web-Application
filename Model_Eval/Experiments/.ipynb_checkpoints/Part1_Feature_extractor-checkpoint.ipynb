{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ee67446-0965-4583-87a0-fe2dc7afcecd",
   "metadata": {},
   "source": [
    "# Assignment_2(ME_698G)\n",
    "### $Monojit~Layek~(21105049)$\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9afc02be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from tensorflow.keras.applications.resnet import ResNet50\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2298e0",
   "metadata": {},
   "source": [
    "# Dataset Image Feature Extractor:\n",
    "   \n",
    "1. Basically, when we use the pixel values as the feature vector.(Pixel Feature folder)\n",
    "    1. All three machine learning models (svm,knn,lr) failed to perform that well.\n",
    "    2. Out of the all three modles svm does better job and have the best accuracy.\n",
    " \n",
    "2. So we use the keras ResNet50 for feature extraction from the train images.\n",
    "    1. Train each model into the resnet50.\n",
    "    2. Remove the soft max output layer.\n",
    "    3. Label the image {1 for dog and 0 for cat.\n",
    "    4. save the array into the directory for traning and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6eb5e276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor(path, filename):\n",
    "            \n",
    "    if(os.path.isfile(filename)):\n",
    "        rsnet_np = np.load(filename)\n",
    "    else:\n",
    "        model = ResNet50(weights = 'imagenet')\n",
    "        # remove the output layer i.e. softmax layer\n",
    "        model = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
    "        rsnet_ftr_lst = []\n",
    "        label = []\n",
    "        for file in os.listdir(path):\n",
    "            # print(file)\n",
    "            #importing the image and resize it to (224*244) \n",
    "            img = cv2.resize(cv2.imread(os.path.join(path, file)), (224, 224))        \n",
    "            img_data = np.expand_dims(img, axis=0)\n",
    "            img_data = preprocess_input(img_data)        \n",
    "            feature = np.array(model.predict(img_data)).flatten()   #train into the resnet50  \n",
    "            rsnet_ftr_lst.append(feature.flatten())\n",
    "            if (file[0:3]==\"cat\")==True:            # cat indicated by 0\n",
    "                label.append(0)\n",
    "            elif (file[0:3]==\"dog\")==True:             # dag indicated by 1\n",
    "                label.append(1)\n",
    "            \n",
    "        label_np = np.array([label], dtype = int)        #label array\n",
    "        rsnet_np = np.array(rsnet_ftr_lst, dtype = float) #feature array\n",
    "        data = np.hstack((rsnet_np,label_np.T))\n",
    "        # save the np array in to the directory\n",
    "        np.save(f\"{filename}\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec72eaf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-17 12:18:30.672691: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fa90040eee0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fa90040eee0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-17 12:18:31.604425: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5h 45min 26s, sys: 7min 35s, total: 5h 53min 2s\n",
      "Wall time: 1h 20min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "image_folder = r\"train/\"\n",
    "#directory path for saving the extracted features\n",
    "data_folder = r\"Feature_extration\"\n",
    "if not(os.path.isdir(data_folder)):\n",
    "        os.mkdir(data_folder)\n",
    "\n",
    "feature_extractor(image_folder, os.path.join(data_folder, \"train.npy\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
